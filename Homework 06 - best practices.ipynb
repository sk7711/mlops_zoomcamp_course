{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. Refactoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create the \"main\" block from which we'll invoke the main function. How does the if statement that we use for this looks like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:    \n",
    "    \n",
    "`if __name__ == '__main__'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Installing pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a folder tests and create two files. One will be the file with tests. We can name if test_batch.py.\n",
    "What should be the other file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:   \n",
    "    \n",
    "`__init__.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. Writing first unit test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows should be there in the expected dataframe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:    \n",
    " `2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code:\n",
    "\n",
    "```python\n",
    "import os,sys\n",
    "sys.path.insert(1, os.path.abspath('.'))\n",
    "\n",
    "import batch\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from deepdiff import DeepDiff\n",
    "\n",
    "def dt(hour, minute, second=0):\n",
    "    return datetime(2021, 1, 1, hour, minute, second)\n",
    "\n",
    "def test_prepare_data():\n",
    "    data = [\n",
    "        (None, None, dt(1, 2), dt(1, 10)),\n",
    "        (1, 1, dt(1, 2), dt(1, 10)),\n",
    "        (1, 1, dt(1, 2, 0), dt(1, 2, 50)),\n",
    "        (1, 1, dt(1, 2, 0), dt(2, 2, 1)),        \n",
    "    ]\n",
    "\n",
    "    columns = ['PUlocationID', 'DOlocationID', 'pickup_datetime', 'dropOff_datetime']\n",
    "    categorical = ['PUlocationID', 'DOlocationID']\n",
    "\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    actual_dict = batch.prepare_data(df, categorical).to_dict(orient='records')\n",
    "    expected_dict = [{'PUlocationID': '-1', 'DOlocationID': '-1', 'pickup_datetime': pd.Timestamp(dt(1, 2)), 'dropOff_datetime': dt(1, 10), 'duration': 8.0}, \n",
    "                     {'PUlocationID':  '1', 'DOlocationID':  '1', 'pickup_datetime': pd.Timestamp(dt(1, 2)), 'dropOff_datetime': dt(1, 10), 'duration': 8.0}]\n",
    "\n",
    "    diff = DeepDiff(actual_dict, expected_dict, ignore_order=True, significant_digits=1)\n",
    "    print(diff)\n",
    "    assert 'type_changes' not in diff.keys()\n",
    "    assert 'values_changed' not in diff.keys()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. Mocking S3 with Localstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust it for localstack. How does the command look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:     \n",
    "`aws --endpoint-url http://localhost:4566 s3 mb s3://nyc-duration`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "docker-compose.yml\n",
    "```\n",
    "services:\n",
    "  localstack:\n",
    "    container_name: hw6\n",
    "    image: localstack/localstack\n",
    "    ports:\n",
    "      - \"4566:4566\"\n",
    "    environment:\n",
    "      - SERVICES=s3\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. Creating test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the size of the file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "`3512`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code for saving dataframe to S3:**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def dt(hour, minute, second=0):\n",
    "    return datetime(2021, 1, 1, hour, minute, second)\n",
    "\n",
    "data = [\n",
    "    (None, None, dt(1, 2), dt(1, 10)),\n",
    "    (1, 1, dt(1, 2), dt(1, 10)),\n",
    "    (1, 1, dt(1, 2, 0), dt(1, 2, 50)),\n",
    "    (1, 1, dt(1, 2, 0), dt(2, 2, 1)),\n",
    "]\n",
    "\n",
    "columns = ['PUlocationID', 'DOlocationID', 'pickup_datetime', 'dropOff_datetime']\n",
    "\n",
    "\n",
    "df_input = pd.DataFrame(data, columns=columns)\n",
    "S3_ENDPOINT_URL = os.getenv('S3_ENDPOINT_URL')\n",
    "options = {'client_kwargs': {'endpoint_url': S3_ENDPOINT_URL}}\n",
    "input_file = 's3://nyc-duration/test_df.parquet'\n",
    "\n",
    "df_input.to_parquet(\n",
    "    input_file,\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False,\n",
    "    storage_options=options\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6. Finish the integration test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the sum of predicted durations for the test dataframe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: `69.28`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**integration_test.py:**\n",
    "\n",
    "```python\n",
    "import os,sys\n",
    "sys.path.insert(1, os.path.abspath('.'))\n",
    "\n",
    "import batch\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from deepdiff import DeepDiff\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def dt(hour, minute, second=0):\n",
    "    return datetime(2021, 1, 1, hour, minute, second)\n",
    "\n",
    "os.system('python batch.py 2021 1')\n",
    "\n",
    "actual_df = batch.read_data('test_df_{year:04d}-{month:02d}_result.parquet'.format(year=2021, month=1))\n",
    "actual_dict = actual_df.to_dict(orient='records')\n",
    "\n",
    "expected_dict = [{'ride_id':'2021/01_0', 'predicted_duration':23.052085},\n",
    "                 {'ride_id':'2021/01_1', 'predicted_duration':46.236612}]\n",
    "\n",
    "expected_df = pd.DataFrame(expected_dict)\n",
    "\n",
    "diff = DeepDiff(actual_dict, expected_dict, significant_digits=1)\n",
    "\n",
    "\n",
    "print('actual_df', actual_df)\n",
    "print('\\n')\n",
    "print('expected_df', expected_df)\n",
    "print('\\n')\n",
    "pprint(f'diff={diff}')\n",
    "\n",
    "assert 'values_changed' not in diff\n",
    "assert 'type_changes' not in diff\n",
    "\n",
    "print('all good')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bae51ec2f5100904fba109799a5d0a322839cf6fe703911623e6033d5c537ccf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
