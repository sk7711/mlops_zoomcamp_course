{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41062d8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T18:25:51.460623Z",
     "start_time": "2022-05-31T18:25:50.054617Z"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c239f77",
   "metadata": {},
   "source": [
    "# Q1. Install MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d7b8f",
   "metadata": {},
   "source": [
    "What's the version that you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eae3ed03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T19:12:58.022126Z",
     "start_time": "2022-05-31T19:12:55.916370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow, version 1.26.1\r\n"
     ]
    }
   ],
   "source": [
    " !mlflow --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558b03c",
   "metadata": {},
   "source": [
    "# Q2. Download and preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b7147",
   "metadata": {},
   "source": [
    "How many files were saved to OUTPUT_FOLDER?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b16f16e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T21:37:03.877272Z",
     "start_time": "2022-05-30T21:37:00.993064Z"
    }
   },
   "outputs": [],
   "source": [
    "!python ./homework/preprocess_data.py --raw_data_path ../data --dest_path ../output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ab68159",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T19:58:34.605397Z",
     "start_time": "2022-05-31T19:58:34.194427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dv.pkl\ttest.pkl  train.pkl  valid.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b1b46",
   "metadata": {},
   "source": [
    "**Answer: 4.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b53bf81",
   "metadata": {},
   "source": [
    "# Q3. Train a model with autolog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6abea9",
   "metadata": {},
   "source": [
    "How many parameters are automatically logged by MLflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dedc00",
   "metadata": {},
   "source": [
    "Train.py contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c4f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def load_pickle(filename: str):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "\n",
    "def run(data_path):\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "        X_valid, y_valid = load_pickle(os.path.join(data_path, \"valid.pkl\"))\n",
    "        rf = RandomForestRegressor(max_depth=10, random_state=0)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_valid)\n",
    "        rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "    mlflow.set_experiment(\"homework-02\")\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        default=\"./output\",\n",
    "        help=\"the location where the processed NYC taxi trip data was saved.\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    run(args.data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ac33e3",
   "metadata": {},
   "source": [
    "Running train.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3e2132",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python homework/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00386e81",
   "metadata": {},
   "source": [
    "Running mlflow UI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe9d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mlflow ui --backend-store-uri sqlite:///mlflow.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d586ee",
   "metadata": {},
   "source": [
    "**Answer: 17**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d227ba",
   "metadata": {},
   "source": [
    "# Question 4: Parameter for launching the tracking server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "012bf8b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T21:19:23.821035Z",
     "start_time": "2022-05-31T21:19:21.697725Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: mlflow server [OPTIONS]\r\n",
      "\r\n",
      "  Run the MLflow tracking server.\r\n",
      "\r\n",
      "  The server listens on http://localhost:5000 by default and only accepts\r\n",
      "  connections from the local machine. To let the server accept connections\r\n",
      "  from other machines, you will need to pass ``--host 0.0.0.0`` to listen on\r\n",
      "  all network interfaces (or a specific interface address).\r\n",
      "\r\n",
      "Options:\r\n",
      "  --backend-store-uri PATH     URI to which to persist experiment and run\r\n",
      "                               data. Acceptable URIs are SQLAlchemy-compatible\r\n",
      "                               database connection strings (e.g.\r\n",
      "                               'sqlite:///path/to/file.db') or local\r\n",
      "                               filesystem URIs (e.g.\r\n",
      "                               'file:///absolute/path/to/directory'). By\r\n",
      "                               default, data will be logged to the ./mlruns\r\n",
      "                               directory.\r\n",
      "  --default-artifact-root URI  Directory in which to store artifacts for any\r\n",
      "                               new experiments created. For tracking server\r\n",
      "                               backends that rely on SQL, this option is\r\n",
      "                               required in order to store artifacts. Note that\r\n",
      "                               this flag does not impact already-created\r\n",
      "                               experiments with any previous configuration of\r\n",
      "                               an MLflow server instance. By default, data\r\n",
      "                               will be logged to the mlflow-artifacts:/ uri\r\n",
      "                               proxy if the --serve-artifacts option is\r\n",
      "                               enabled. Otherwise, the default location will\r\n",
      "                               be ./mlruns.\r\n",
      "  --serve-artifacts            If specified, enables serving of artifact\r\n",
      "                               uploads, downloads, and list requests by\r\n",
      "                               routing these requests to the storage location\r\n",
      "                               that is specified by '--artifact-destination'\r\n",
      "                               directly through a proxy. The default location\r\n",
      "                               that these requests are served from is a local\r\n",
      "                               './mlartifacts' directory which can be\r\n",
      "                               overridden via the '--artifacts-destination'\r\n",
      "                               argument. Default: False\r\n",
      "  --artifacts-only             If specified, configures the mlflow server to\r\n",
      "                               be used only for proxied artifact serving. With\r\n",
      "                               this mode enabled, functionality of the mlflow\r\n",
      "                               tracking service (e.g. run creation, metric\r\n",
      "                               logging, and parameter logging) is disabled.\r\n",
      "                               The server will only expose endpoints for\r\n",
      "                               uploading, downloading, and listing artifacts.\r\n",
      "                               Default: False\r\n",
      "  --artifacts-destination URI  The base artifact location from which to\r\n",
      "                               resolve artifact upload/download/list requests\r\n",
      "                               (e.g. 's3://my-bucket'). Defaults to a local\r\n",
      "                               './mlartifacts' directory. This option only\r\n",
      "                               applies when the tracking server is configured\r\n",
      "                               to stream artifacts and the experiment's\r\n",
      "                               artifact root location is http or mlflow-\r\n",
      "                               artifacts URI.\r\n",
      "  -h, --host HOST              The network address to listen on (default:\r\n",
      "                               127.0.0.1). Use 0.0.0.0 to bind to all\r\n",
      "                               addresses if you want to access the tracking\r\n",
      "                               server from other machines.\r\n",
      "  -p, --port INTEGER           The port to listen on (default: 5000).\r\n",
      "  -w, --workers TEXT           Number of gunicorn worker processes to handle\r\n",
      "                               requests (default: 4).\r\n",
      "  --static-prefix TEXT         A prefix which will be prepended to the path of\r\n",
      "                               all static paths.\r\n",
      "  --gunicorn-opts TEXT         Additional command line options forwarded to\r\n",
      "                               gunicorn processes.\r\n",
      "  --waitress-opts TEXT         Additional command line options for waitress-\r\n",
      "                               serve.\r\n",
      "  --expose-prometheus TEXT     Path to the directory where metrics will be\r\n",
      "                               stored. If the directory doesn't exist, it will\r\n",
      "                               be created. Activate prometheus exporter to\r\n",
      "                               expose metrics on /metrics endpoint.\r\n",
      "  --help                       Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "! mlflow server --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb3484",
   "metadata": {},
   "source": [
    "**Answer: default-artifact-root**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac7b25",
   "metadata": {},
   "source": [
    "# Question 5: RMSE with hyperopt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d324c058",
   "metadata": {},
   "source": [
    "hpo.py contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab962e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from hyperopt.pyll import scope\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"random-forest-hyperopt\")\n",
    "\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "\n",
    "def run(data_path, num_trials):\n",
    "\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_valid, y_valid = load_pickle(os.path.join(data_path, \"valid.pkl\"))\n",
    "\n",
    "    def objective(params):\n",
    "        with mlflow.start_run():\n",
    "            mlflow.set_tag(\"model\", \"xgboost\")\n",
    "            mlflow.log_params(params)\n",
    "            rf = RandomForestRegressor(**params)\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_pred = rf.predict(X_valid)\n",
    "            rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "            return {'loss': rmse, 'status': STATUS_OK}\n",
    "\n",
    "    search_space = {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
    "        'n_estimators': scope.int(hp.quniform('n_estimators', 10, 50, 1)),\n",
    "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
    "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 4, 1)),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    rstate = np.random.default_rng(42)  # for reproducible results\n",
    "    fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=num_trials,\n",
    "        trials=Trials(),\n",
    "        rstate=rstate\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        default=\"./output\",\n",
    "        help=\"the location where the processed NYC taxi trip data was saved.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_evals\",\n",
    "        default=50,\n",
    "        help=\"the number of parameter evaluations for the optimizer to explore.\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    run(args.data_path, args.max_evals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc553d",
   "metadata": {},
   "source": [
    "**Answer: 6.628**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35926303",
   "metadata": {},
   "source": [
    "# Question 6: RMSE on test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6ccaec",
   "metadata": {},
   "source": [
    "register_model.py contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9d4108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import mlflow\n",
    "from hyperopt import hp, space_eval\n",
    "from hyperopt.pyll import scope\n",
    "from mlflow.entities import ViewType\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "HPO_EXPERIMENT_NAME = \"random-forest-hyperopt\"\n",
    "EXPERIMENT_NAME = \"random-forest-best-models\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "SPACE = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 10, 50, 1)),\n",
    "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
    "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 4, 1)),\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "\n",
    "def train_and_log_model(data_path, params):\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_valid, y_valid = load_pickle(os.path.join(data_path, \"valid.pkl\"))\n",
    "    X_test, y_test = load_pickle(os.path.join(data_path, \"test.pkl\"))\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        params = space_eval(SPACE, params)\n",
    "        rf = RandomForestRegressor(**params)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # evaluate model on the validation and test sets\n",
    "        valid_rmse = mean_squared_error(y_valid, rf.predict(X_valid), squared=False)\n",
    "        mlflow.log_metric(\"valid_rmse\", valid_rmse)\n",
    "        test_rmse = mean_squared_error(y_test, rf.predict(X_test), squared=False)\n",
    "        mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "\n",
    "def run(data_path, log_top):\n",
    "\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # retrieve the top_n model runs and log the models to MLflow\n",
    "    experiment = client.get_experiment_by_name(HPO_EXPERIMENT_NAME)\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=experiment.experiment_id,\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=log_top,\n",
    "        order_by=[\"metrics.rmse ASC\"]\n",
    "    )\n",
    "    for run in runs:\n",
    "        train_and_log_model(data_path=data_path, params=run.data.params)\n",
    "\n",
    "    # select the model with the lowest test RMSE\n",
    "    experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    best_run = client.search_runs(\n",
    "                experiment_ids=experiment.experiment_id,\n",
    "                run_view_type=ViewType.ACTIVE_ONLY,\n",
    "                max_results=1,\n",
    "                order_by=[\"metrics.rmse ASC\"]\n",
    "    )\n",
    "    # register the best model\n",
    "    run_id = best_run[0].info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    mlflow.register_model(model_uri=model_uri, name=\"good_one\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        default=\"./output\",\n",
    "        help=\"the location where the processed NYC taxi trip data was saved.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--top_n\",\n",
    "        default=5,\n",
    "        type=int,\n",
    "        help=\"the top 'top_n' models will be evaluated to decide which model to promote.\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    run(args.data_path, args.top_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cf6f56",
   "metadata": {},
   "source": [
    "**Answer: 6.55**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0848c9d6c7d415ad6c477ff7ff8e98694d1a4aa96d0deee89244642e6b630036"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "187.567px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
