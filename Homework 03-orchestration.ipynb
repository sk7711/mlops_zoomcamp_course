{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9155db95",
   "metadata": {},
   "source": [
    "# Q1. Converting the script to a Prefect flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea56d1d2",
   "metadata": {},
   "source": [
    "After adding all of the decorators, there is actually one task that you will need to call .result() for inside the flow to get it to work. Which task is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28920bc4",
   "metadata": {},
   "source": [
    "Answer: **train_model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff502f",
   "metadata": {},
   "source": [
    "# Q2. Parameterizing the flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d5e30d",
   "metadata": {},
   "source": [
    "The validation MSE is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a676299",
   "metadata": {},
   "source": [
    "Answer: **11.637**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b367e3c",
   "metadata": {},
   "source": [
    "# Q3. Saving the model and artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56969c7",
   "metadata": {},
   "source": [
    "What is the file size of the DictVectorizer that we trained when the date is 2021-08-15?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a5d7db",
   "metadata": {},
   "source": [
    "Answer: **13,000 bytes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b97fd5",
   "metadata": {},
   "source": [
    "# Q4. Creating a deployment with a CronSchedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46738596",
   "metadata": {},
   "source": [
    "What is the Cron expression to run a flow at 9 AM every 15th of the month?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576b89a6",
   "metadata": {},
   "source": [
    "Answer: **0915xx**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be571ec0",
   "metadata": {},
   "source": [
    "# Q5. Viewing the Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd57f4d",
   "metadata": {},
   "source": [
    "How many flow runs are scheduled by Prefect in advance? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8905ffbc",
   "metadata": {},
   "source": [
    "Answer: **3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b901d",
   "metadata": {},
   "source": [
    "# Q6. Creating a work-queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64d0e59",
   "metadata": {},
   "source": [
    "What is the command to view the available work-queues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bf59aa",
   "metadata": {},
   "source": [
    "Answer: **prefect work-queue preview -h 3000 59472d4c-4703-48cb-9653-b8af9309c52b**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b01b6dd",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a3a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "from prefect import task, flow, get_run_logger\n",
    "from prefect.deployments import DeploymentSpec\n",
    "from prefect.orion.schemas.schedules import CronSchedule\n",
    "from prefect.flow_runners import SubprocessFlowRunner\n",
    "from datetime import timedelta\n",
    "from prefect.task_runners import SequentialTaskRunner\n",
    "\n",
    "\n",
    "@task\n",
    "def read_data(path):\n",
    "    logger = get_run_logger('read_data')\n",
    "    df = pd.read_parquet(path)\n",
    "    return df\n",
    "\n",
    "@task\n",
    "def prepare_features(df, categorical, train=True):\n",
    "    logger = get_run_logger()\n",
    "    df['duration'] = df.dropOff_datetime - df.pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    mean_duration = df.duration.mean()\n",
    "    if train:\n",
    "        print(f\"The mean duration of training is {mean_duration}\")\n",
    "    else:\n",
    "        print(f\"The mean duration of validation is {mean_duration}\")\n",
    "    \n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "    return df\n",
    "\n",
    "@task\n",
    "def train_model(df, categorical):\n",
    "    logger = get_run_logger('train_model')\n",
    "    train_dicts = df[categorical].to_dict(orient='records')\n",
    "    dv = DictVectorizer()\n",
    "    X_train = dv.fit_transform(train_dicts) \n",
    "    y_train = df.duration.values\n",
    "\n",
    "    print(f\"The shape of X_train is {X_train.shape}\")\n",
    "    print(f\"The DictVectorizer has {len(dv.feature_names_)} features\")\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, y_pred, squared=False)\n",
    "    print(f\"The MSE of training is: {mse}\")\n",
    "    return lr, dv\n",
    "\n",
    "@task\n",
    "def run_model(df, categorical, dv, lr):\n",
    "    logger = get_run_logger('run_model')\n",
    "    val_dicts = df[categorical].to_dict(orient='records')\n",
    "    X_val = dv.transform(val_dicts) \n",
    "    y_pred = lr.predict(X_val)\n",
    "    y_val = df.duration.values\n",
    "\n",
    "    mse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    print(f\"The MSE of validation is: {mse}\")\n",
    "    return\n",
    "\n",
    "@task\n",
    "def get_paths(date=None):\n",
    "    logger = get_run_logger('get_paths')\n",
    "    if date is None:\n",
    "        date = pd.Timestamp.now()\n",
    "    date_train = (pd.Timestamp(date) - pd.Timedelta(days=60)).strftime('%Y-%m')\n",
    "    date_val = (pd.Timestamp(date) - pd.Timedelta(days=30)).strftime('%Y-%m')\n",
    "    train_path = f\"../data/fhv_tripdata_{date_train}.parquet\"\n",
    "    val_path = f\"../data/fhv_tripdata_{date_val}.parquet\"\n",
    "    return train_path, val_path\n",
    "\n",
    "\n",
    "\n",
    "@flow(task_runner=SequentialTaskRunner())\n",
    "def main(date=None):\n",
    "\n",
    "    train_path, val_path = get_paths(date).result()\n",
    "    categorical = ['PUlocationID', 'DOlocationID']\n",
    "\n",
    "    df_train = read_data(train_path)\n",
    "    df_train_processed = prepare_features(df_train, categorical)\n",
    "\n",
    "    df_val = read_data(val_path)\n",
    "    df_val_processed = prepare_features(df_val, categorical, False)\n",
    "\n",
    "    # train the model\n",
    "    lr, dv = train_model(df_train_processed, categorical).result()\n",
    "    date2 = pd.Timestamp(date).strftime('%Y-%m-%d')\n",
    "\n",
    "    joblib.dump(lr, 'model-'+date2+'.bin')\n",
    "    joblib.dump(dv, 'dv-'+date2+'.b')\n",
    "    run_model(df_val_processed, categorical, dv, lr)\n",
    "\n",
    "\n",
    "DeploymentSpec(\n",
    "    flow=main,\n",
    "    name='model_training',\n",
    "    schedule=CronSchedule(cron='0 9 15 * *'),\n",
    "    flow_runner=SubprocessFlowRunner())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
